# New state space: 10 monitors + 1 matrix index + previous layer (each layer = 20 pixels in +y direction)
# Total: 10 + 1 + 20 = 31
state_dim: &state_dim 31
num_monitors: &num_monitors 10
num_previous_layers: &num_previous_layers 3

environment:
  obs_size: *state_dim
  action_size: 20
  max_steps: 20
  num_previous_layers: *num_previous_layers


simulation:
  resolution: 20
  wavelength: 1.55
  cell_size: [6, 4, 0]
  pml_thickness: 0.2
  waveguide_width: 0.4
  waveguide_index: 3.45
  waveguide_center_x: -0.9
  waveguide_length: 1.8
  output_y_separation: 0.6
  simulation_time: 200
  num_flux_regions: *num_monitors  # Now 10 monitors instead of 80
  monitor_length: 0.2  # Length of each monitor in um
  state_output_x: 1.0
  design_region_x: 2.0
  design_region_y: 2.0
  design_region_y_min: -1.0  # Minimum y position for monitor placement
  design_region_y_max: 1.0   # Maximum y position for monitor placement
  pixel_size: 0.1
  silicon_index: 3.45
  silica_index: 1.45
  pixel_num_x: 20
  pixel_num_y: 20
  src_pos_shift_coeff: 0.95
  input_coupler_length: 1.5
  output_coupler_length: 1.5
  input_flux_monitor_x: -1.5
  output_flux_monitor_x: 2


training:
  ppo:
    total_timesteps: 512000
    # total_timesteps: 640
    n_envs: 16
    learning_rate: 0.0003
    n_steps: 240       # multiple of 20; rollout_len = n_envs * n_steps = 3840
    batch_size: 256    # larger batch to smooth updates
    n_epochs: 20       # reduce epochs to avoid overfitting each batch
    gamma: 0.99
    gae_lambda: 0.95
    clip_range: 0.2
    ent_coef: 0.005
    vf_coef: 0.5
    max_grad_norm: 0.5
    tensorboard_log: ./ppo_tensorboard/
    save_path: models/
  sac:
    total_timesteps: 1000000
    n_envs: 1
    learning_rate: 0.0003 # 0.0001 0.0003 0.001
    buffer_size: 256
    learning_starts: 100
    tau: 0.005
    gamma: 0.99
    train_freq: 20
    gradient_steps: 2
    ent_coef: auto
    target_update_interval: 2
    target_entropy: auto
    use_sde: false
    tensorboard_log: ./sac_tensorboard/
    save_path: models/sac_model