# New state space: 10 monitors + 1 matrix index + previous layer (each layer = 20 pixels in +y direction)
# Total: 10 + 1 + 20 = 31
state_dim: &state_dim 31
num_monitors: &num_monitors 10
num_previous_layers: &num_previous_layers 3

environment:
  obs_size: *state_dim
  action_size: 20
  max_steps: 20
  num_previous_layers: *num_previous_layers
  target_ratio: 0.5  # Target ratio for output 1 (70% to output 1, 30% to output 2)


simulation:
  resolution: 20
  wavelength: 1.55
  cell_size: [6, 4, 0]
  pml_thickness: 0.2
  waveguide_width: 0.4
  waveguide_index: 3.45
  waveguide_center_x: -0.9
  waveguide_length: 1.8
  output_y_separation: 0.6
  simulation_time: 200
  num_flux_regions: *num_monitors  # Now 10 monitors instead of 80
  monitor_length: 0.2  # Length of each monitor in um
  state_output_x: 1.0
  design_region_x: 2.0
  design_region_y: 2.0
  design_region_y_min: -1.0  # Minimum y position for monitor placement
  design_region_y_max: 1.0   # Maximum y position for monitor placement
  pixel_size: 0.1
  silicon_index: 3.45
  silica_index: 1.45
  pixel_num_x: 20
  pixel_num_y: 20
  src_pos_shift_coeff: 0.95
  input_coupler_length: 1.5
  output_coupler_length: 1.5
  input_flux_monitor_x: -1.5
  output_flux_monitor_x: 2
  # Fixed y-axis range for plotting (set to null/empty to use auto scaling)
  plot_design_ylim: [0, 25]  # e.g., [0, 1.0] to fix y-axis range for design plot
  plot_distribution_ylim: [0, 120000]  # e.g., [0, 1.0] to fix y-axis range for distribution plot
  plot_full_distribution_ylim: [0, 120000]  # e.g., [0, 2.0] to fix y-axis range for full distribution plot


training:
  ppo:
    # total_timesteps: 192000
    # n_envs: 1
    # learning_rate: 0.001
    # n_steps: 80
    # batch_size: 64
    # n_epochs: 40
    total_timesteps: 2000000
    n_envs: 64
    learning_rate: 0.0001
    n_steps: 60       # multiple of 20; rollout_len = n_envs * n_steps = 3840
    batch_size: 480    # larger batch to smooth updates
    n_epochs: 20       # reduce epochs to avoid overfitting each batch
    gamma: 0.99
    gae_lambda: 0.95
    clip_range: 0.2
    ent_coef: 0.005
    # ent_coef: 0.01
    vf_coef: 0.5
    max_grad_norm: 0.5
    use_cnn: true
    tensorboard_log: ./ppo_tensorboard/
    load_model_path: /storage/undergrad/b12901074/RL_FinalProject/models/ppo_model_20251218_135815_best.zip
    # load_model_path: ""
    save_path: models/
  a2c:
    total_timesteps: 960000
    n_envs: 16
    learning_rate: 0.0001
    n_steps: 240       # multiple of 20; rollout_len = n_envs * n_steps = 3840
    gamma: 0.99
    gae_lambda: 0.95
    ent_coef: 0.01
    vf_coef: 0.5
    max_grad_norm: 0.5
    use_cnn: true
    tensorboard_log: ./a2c_tensorboard/
    load_model_path: ""
    save_path: models/
  sac:
    total_timesteps: 1000000
    n_envs: 1
    learning_rate: 0.0003 # 0.0001 0.0003 0.001
    buffer_size: 256
    learning_starts: 100
    tau: 0.005
    gamma: 0.99
    train_freq: 20
    gradient_steps: 2
    ent_coef: auto
    target_update_interval: 2
    target_entropy: auto
    use_sde: false
    tensorboard_log: ./sac_tensorboard/
    save_path: models/sac_model